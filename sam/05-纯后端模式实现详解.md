# 纯后端模式实现详解

> 基于 SAM1，从一张图片开始，到前端展示 Mask 的完整流程

---

## 全流程总览

```
用户选择图片
    │
    ▼
┌──────────────────────────────────────────────────────────────────┐
│ 前端 (Vue 3)                                                     │
│                                                                   │
│  1. File → blob URL (本地预览)                                   │
│  2. File → POST /api/upload (上传到后端)                          │
│  3. 用户点击画布 → 坐标转换                                      │
│  4. POST /api/segment { image_url, points }                      │
│  5. 收到 base64 PNG mask → 解码 → Canvas 叠加绘制               │
│                                                                   │
└──────────────────────────────────────────────────────────────────┘
                    │                              ▲
                    │ HTTP                         │ HTTP
                    ▼                              │
┌──────────────────────────────────────────────────────────────────┐
│ 后端 (FastAPI + PyTorch)                                         │
│                                                                   │
│  1. 接收图片 → 存储到 uploads/                                   │
│  2. 接收分割请求 → 加载图片为 numpy                               │
│  3. SAM1 Encoder → Embedding [1,256,64,64]                       │
│  4. SAM1 Decoder → 3 个候选 Mask                                 │
│  5. 选最佳 Mask → 转 RGBA PNG → base64 返回                     │
│                                                                   │
└──────────────────────────────────────────────────────────────────┘
```

---

## 第一步：用户选择图片 → 前端处理

### 发生了什么

用户在页面上选择一张图片文件，前端需要做两件事：
1. **本地预览**：创建 blob URL 供 Canvas 显示
2. **上传到后端**：后端分割时需要访问这张图片

### 关键代码

```typescript
// ImageUploader.vue - 用户选了文件后
function handleFile(file: File) {
  // 1. 创建本地预览 URL（不经过网络，瞬间完成）
  const url = URL.createObjectURL(file)
  
  // 2. 获取图片尺寸（后续坐标转换要用）
  const img = new Image()
  img.onload = () => {
    // url = blob:http://localhost:5173/xxx  (本地预览用)
    // file = 原始文件对象                   (上传到后端用)
    store.setImage(url, img.width, img.height, file)
  }
  img.src = url
}
```

### 数据流

```
用户选择 photo.jpg (1920×1080, 500KB)
    │
    ├─→ blob URL: blob:http://localhost:5173/a1b2c3  (本地预览)
    │
    └─→ File 对象: { name: "photo.jpg", size: 512000, type: "image/jpeg" }
```

---

## 第二步：上传图片到后端

### 发生了什么

前端将文件通过 multipart/form-data 上传到后端。后端保存到 `uploads/` 目录，返回一个可访问的 URL。

### 关键代码

```typescript
// store/app.ts - setImage 方法
async function setImage(url, width, height, file) {
  imageUrl.value = url           // blob URL，供 Canvas 显示用
  imageSize.value = { width, height }
  
  // 上传到后端，拿到服务器 URL
  const remoteUrl = await apiClient.uploadImage(file)
  // remoteUrl = "/uploads/a1b2c3.jpg"
  
  // 告诉 BackendOnlyMode 记住这个 URL
  await mode.value.setImage(remoteUrl)
  
  imageLoaded.value = true  // 触发画布显示
}
```

```python
# 后端 upload.py - 保存文件
@router.post("/upload")
async def upload_image(file: UploadFile):
    filename = f"{uuid4().hex}.{ext}"
    filepath = os.path.join(UPLOAD_DIR, filename)
    with open(filepath, "wb") as f:
        f.write(await file.read())
    return {"url": f"/uploads/{filename}"}
```

### 数据流

```
前端 File 对象
    │
    │  POST /api/upload (multipart/form-data)
    ▼
后端保存到 backend/uploads/a1b2c3.jpg
    │
    │  返回 {"url": "/uploads/a1b2c3.jpg"}
    ▼
前端存储两个 URL:
  - imageUrl = blob:xxx        (Canvas 显示用)
  - serverImageUrl = /uploads/xxx  (API 调用用)
```

---

## 第三步：图片显示到 Canvas

### 发生了什么

`imageLoaded` 变为 `true` 后，DrawCanvas 组件将 blob URL 加载为 Image 对象，计算缩放比例，绘制到 Canvas 上。

### 关键代码

```typescript
// DrawCanvas.vue
function preloadImage(url: string) {
  const img = new Image()
  img.onload = () => {
    loadedImage = img
    tryDraw()   // 图片加载好了，尝试绘制
  }
  img.src = url  // blob:xxx
}

function drawToCanvas() {
  // 1. 获取容器尺寸（页面中画布区域的大小）
  const rect = container.getBoundingClientRect()
  
  // 2. 计算等比缩放（图片不能超出容器）
  const scale = Math.min(
    (rect.width - 40) / img.width,
    (rect.height - 40) / img.height,
    1  // 不放大，只缩小
  )
  const w = Math.round(img.width * scale)
  const h = Math.round(img.height * scale)
  
  // 3. 设置 Canvas 像素尺寸
  canvas.width = w
  canvas.height = h
  
  // 4. 绘制图片
  ctx.drawImage(img, 0, 0, w, h)
}
```

### 尺寸关系

```
原始图片:    1920 × 1080
容器大小:    1000 × 700   (浏览器窗口中 canvas-area 的大小)
缩放比:     min(960/1920, 660/1080, 1) = 0.5
Canvas:     960 × 540     (实际绘制的像素大小)

三层画布叠加:
┌─────────────────────┐
│  Canvas (图片层)     │  z-index: 1
│  Canvas (Mask 层)    │  z-index: 2, 半透明
│  Div (交互层)        │  z-index: 3, 接收点击
└─────────────────────┘
```

---

## 第四步：用户点击 → 坐标转换

### 发生了什么

用户在画布上点击一个位置。但画布是缩放过的，需要将屏幕坐标转换回原图坐标，SAM 才能正确分割。

### 关键代码

```typescript
// DrawCanvas.vue
function handleClick(e: MouseEvent) {
  const el = e.currentTarget as HTMLElement
  const rect = el.getBoundingClientRect()

  // 1. 获取点击在画布内的位置（像素）
  const canvasX = e.clientX - rect.left   // 例: 480
  const canvasY = e.clientY - rect.top    // 例: 270

  // 2. 换算回原图坐标
  const scaleX = store.imageSize.width / displaySize.width    // 1920/960 = 2
  const scaleY = store.imageSize.height / displaySize.height  // 1080/540 = 2
  const x = canvasX * scaleX   // 480 * 2 = 960
  const y = canvasY * scaleY   // 270 * 2 = 540

  // 3. 左键=前景(1), 右键=背景(0)
  const type = e.button === 2 ? 0 : 1

  // 4. 发送分割请求
  store.addPointAndSegment({ x: 960, y: 540, type: 1 })
}
```

### 坐标转换图解

```
屏幕坐标空间 (CSS 像素)           原图坐标空间 (SAM 需要的)
┌─────────────────┐              ┌─────────────────────────┐
│                 │              │                         │
│     点击位置     │    ×2       │        SAM 需要的坐标    │
│   (480, 270)    │ ─────────→  │       (960, 540)        │
│                 │              │                         │
│    960×540      │              │       1920×1080         │
└─────────────────┘              └─────────────────────────┘
```

---

## 第五步：后端接收请求 → SAM 分割

### 发生了什么

这是核心步骤。后端收到图片 URL 和点击坐标后，执行 SAM1 的完整推理流程。

### 5.1 加载模型（只在第一次请求时执行）

```python
# sam1_manager.py
from segment_anything import sam_model_registry, SamPredictor

# sam_model_registry 是 SAM 官方提供的模型注册表
# 根据 model_type ("vit_b") 找到对应的网络结构
sam = sam_model_registry["vit_b"](checkpoint="models/sam_vit_b_01ec64.pth")

# .pth 文件包含:
# - Image Encoder (ViT-B) 的权重: 91M 参数
# - Prompt Encoder 的权重
# - Mask Decoder 的权重
# 总计约 375MB

sam.to("mps")  # 移到 GPU (Mac 用 MPS, NVIDIA 用 cuda)
sam.eval()      # 推理模式（关闭 dropout 等训练行为）

# SamPredictor 是 SAM 官方封装的推理工具
# 内部管理: 图片预处理、Embedding 缓存、坐标变换
predictor = SamPredictor(sam)
```

### 5.2 加载并预处理图片

```python
# image_loader.py
image = Image.open(filepath).convert("RGB")
image = np.array(image)
# image.shape = (1080, 1920, 3)  → H×W×C, uint8, RGB

# SamPredictor.set_image 内部做的事:
predictor.set_image(image)
# 内部流程:
#   1. 缩放到 1024×1024 (长边对齐，短边填充)
#   2. 归一化: (pixel/255 - mean) / std
#   3. 转为 tensor: [1, 3, 1024, 1024]
#   4. 通过 Image Encoder (ViT-B) → Embedding
#   5. 缓存 Embedding (后续点击不用重新编码)
```

### 5.3 SAM 内部的两阶段处理

```
┌──────────────────────────────────────────────────────────────┐
│  set_image(image) 时执行 — 慢（600-2000ms）                    │
│                                                               │
│  原图 [1080, 1920, 3]                                         │
│      │                                                        │
│      ▼ resize + pad                                           │
│  [1, 3, 1024, 1024]  (BCHW, float32, 归一化)                 │
│      │                                                        │
│      ▼ ViT-B Image Encoder (91M 参数, 12 层 Transformer)     │
│  Embedding [1, 256, 64, 64]  ← 缓存在 predictor 内部         │
│                                                               │
│  这一步做了什么:                                              │
│  - 把 1024×1024 的图片压缩成 64×64 的特征图                   │
│  - 每个位置有 256 维特征，包含"这里是什么"的语义信息           │
│  - 图片分辨率降低了 16 倍 (1024/64=16)                        │
│                                                               │
└──────────────────────────────────────────────────────────────┘
                          │
                          ▼ (缓存，后续跳过)
┌──────────────────────────────────────────────────────────────┐
│  predict(points, labels) 时执行 — 快（10-50ms）               │
│                                                               │
│  点击坐标 [[960, 540]]                                        │
│      │                                                        │
│      ▼ Prompt Encoder                                         │
│  将点击坐标编码为 prompt token                                │
│  (坐标归一化 + 位置编码 + 前景/背景标签)                      │
│      │                                                        │
│      ▼ Mask Decoder (轻量级, 两层 Transformer)                │
│                                                               │
│  输入:                                                        │
│  - Embedding [1, 256, 64, 64]  (图片特征)                    │
│  - Prompt tokens              (点击编码)                      │
│                                                               │
│  输出:                                                        │
│  - masks [3, 256, 256]    (3 个候选 mask, 低分辨率)           │
│  - scores [3]             (每个 mask 的质量分数)              │
│      │                                                        │
│      ▼ 上采样到原图大小                                       │
│  masks [3, 1080, 1920]    (二值图, bool)                     │
│                                                               │
└──────────────────────────────────────────────────────────────┘
```

### 5.4 为什么输出 3 个 Mask？

```
SAM 的 multimask_output=True 会输出 3 个候选:

假设用户点击了一只猫的眼睛:

Mask 1 (score: 0.95): 只有眼睛           ← 最小的语义范围
Mask 2 (score: 1.02): 猫的头部           ← 中等语义范围
Mask 3 (score: 0.87): 整只猫             ← 最大的语义范围

我们取 score 最高的那个:
best_idx = np.argmax(scores)  → 1 (猫头)
best_mask = masks[1]
```

### 5.5 Mask 后处理 → base64 PNG

```python
# segment.py
def mask_to_base64_png(mask: np.ndarray) -> str:
    """
    mask: [1080, 1920], dtype=bool
    True = 这个像素属于目标
    False = 背景
    """
    h, w = mask.shape  # 1080, 1920
    
    # 创建 RGBA 图像（4 通道: R, G, B, Alpha）
    rgba = np.zeros((h, w, 4), dtype=np.uint8)
    
    # 目标区域: 半透明蓝色
    rgba[mask > 0] = [30, 144, 255, 128]
    #                  R    G    B    A
    #                 蓝色         半透明(128/255≈50%)
    
    # 背景区域: [0, 0, 0, 0] = 完全透明
    
    # 转为 PNG 图片 → base64 字符串
    img = Image.fromarray(rgba, 'RGBA')
    buf = BytesIO()
    img.save(buf, format='PNG')
    return base64.b64encode(buf.getvalue()).decode()
    # 输出: "iVBORw0KGgoAAAANSUhEU..." (约 2-50KB)
```

### 完整 API 响应

```json
{
  "mask": "iVBORw0KGgoAAAANSUhEU...",  // base64 PNG
  "mask_size": [1080, 1920],
  "score": 1.0166,
  "time_ms": 687,
  "model": "sam1_vit_b"
}
```

---

## 第六步：前端接收 Mask → Canvas 叠加显示

### 发生了什么

前端收到 base64 PNG 字符串，解码为 ImageData，绘制到 Mask Canvas 层上，与原图叠加显示。

### 6.1 base64 → ImageData

```typescript
// BackendOnlyMode.ts
private base64PngToImageData(base64: string): Promise<ImageData> {
  return new Promise((resolve) => {
    const img = new Image()
    img.onload = () => {
      // 用 OffscreenCanvas 获取像素数据
      const canvas = new OffscreenCanvas(img.width, img.height)
      const ctx = canvas.getContext('2d')!
      ctx.drawImage(img, 0, 0)
      resolve(ctx.getImageData(0, 0, img.width, img.height))
      // ImageData: { width: 1920, height: 1080, data: Uint8ClampedArray }
      // data 是 RGBA 像素数组, 长度 = 1920 × 1080 × 4
    }
    img.src = `data:image/png;base64,${base64}`
  })
}
```

### 6.2 绘制到 Mask Canvas

```typescript
// DrawCanvas.vue
watch(() => store.currentMask, (maskResult) => {
  const ctx = maskCanvas.getContext('2d')!
  ctx.clearRect(0, 0, maskCanvas.width, maskCanvas.height)  // 先清空

  if (maskResult) {
    // mask 是原图尺寸 (1920×1080), 但 canvas 是缩放后的 (960×540)
    // 需要通过临时 canvas 缩放绘制
    const temp = new OffscreenCanvas(maskResult.mask.width, maskResult.mask.height)
    const tempCtx = temp.getContext('2d')!
    tempCtx.putImageData(maskResult.mask, 0, 0)

    // 自动缩放到 maskCanvas 大小
    ctx.drawImage(temp, 0, 0, maskCanvas.width, maskCanvas.height)
  }
})
```

### 6.3 三层叠加效果

```
┌────────────────────────────────────────┐
│                                        │
│   图片 Canvas (z-index: 1)             │
│   ┌──────────────────────────────┐     │
│   │  原始图片                    │     │
│   │  ctx.drawImage(img, ...)     │     │
│   └──────────────────────────────┘     │
│                                        │
│   Mask Canvas (z-index: 2)             │
│   ┌──────────────────────────────┐     │
│   │  半透明蓝色覆盖              │     │
│   │  RGBA(30,144,255,128)        │     │
│   │  pointer-events: none        │     │
│   └──────────────────────────────┘     │
│                                        │
│   交互 Div (z-index: 3)               │
│   ┌──────────────────────────────┐     │
│   │  接收点击事件                │     │
│   │  显示绿/红标记点             │     │
│   │  cursor: crosshair           │     │
│   └──────────────────────────────┘     │
│                                        │
└────────────────────────────────────────┘

视觉效果:
- 用户看到原图 + 蓝色半透明遮罩 + 点击标记
- 点击穿透到交互层处理
- Mask 层不拦截点击事件
```

---

## 完整时序图

```
用户                    前端                        后端 (FastAPI)             SAM1
 │                      │                           │                         │
 │  选择图片 photo.jpg  │                           │                         │
 │─────────────────────>│                           │                         │
 │                      │                           │                         │
 │                      │ blob URL → Canvas 显示    │                         │
 │                      │                           │                         │
 │                      │ POST /api/upload          │                         │
 │                      │──────────────────────────>│                         │
 │                      │                           │ 保存到 uploads/         │
 │                      │    {url: "/uploads/xxx"}  │                         │
 │                      │<──────────────────────────│                         │
 │                      │                           │                         │
 │  看到图片            │                           │                         │
 │<─────────────────────│                           │                         │
 │                      │                           │                         │
 │  左键点击 (480,270)  │                           │                         │
 │─────────────────────>│                           │                         │
 │                      │                           │                         │
 │                      │ 坐标转换: (960,540)       │                         │
 │                      │                           │                         │
 │                      │ POST /api/segment         │                         │
 │                      │ {image_url, points}       │                         │
 │                      │──────────────────────────>│                         │
 │                      │                           │ load_image()            │
 │                      │                           │────────────────────────>│
 │                      │                           │                         │
 │                      │                           │ predictor.set_image()   │
 │                      │                           │ (Image Encoder, 600ms)  │
 │                      │                           │                         │
 │                      │                           │ predictor.predict()     │
 │                      │                           │ (Mask Decoder, 20ms)    │
 │                      │                           │                         │
 │                      │                           │ masks[3,1080,1920]      │
 │                      │                           │<────────────────────────│
 │                      │                           │                         │
 │                      │                           │ 选最佳 mask             │
 │                      │                           │ → RGBA PNG              │
 │                      │                           │ → base64                │
 │                      │                           │                         │
 │                      │  {mask: "iVBOR...",       │                         │
 │                      │   score: 1.02,            │                         │
 │                      │   time_ms: 687}           │                         │
 │                      │<──────────────────────────│                         │
 │                      │                           │                         │
 │                      │ base64 → ImageData        │                         │
 │                      │ → drawImage (Mask Canvas) │                         │
 │                      │                           │                         │
 │  看到蓝色遮罩        │                           │                         │
 │<─────────────────────│                           │                         │
```

---

## 关键设计决策

### 为什么用 base64 PNG 传输 Mask，而不是 RLE？

```
选项对比:

方式          体积       前端处理       复杂度
─────────    ─────      ──────────    ────────
RLE 字符串   ~2KB       需要解码逻辑   中等
base64 PNG   ~5-50KB    直接用 Image   极简 ✅
raw 像素     ~4MB       需要重建       复杂

选择 base64 PNG 的原因:
1. 前端直接用 new Image() 加载，无需手写解码
2. PNG 自带无损压缩，体积可接受
3. 后端 Pillow 一行代码搞定
4. 调试方便（直接在浏览器查看）
```

### 为什么前端用两个 URL？

```
imageUrl (blob:xxx)         → 给 Canvas 显示用
serverImageUrl (/uploads/xxx) → 给后端 API 用

原因:
- blob URL 是浏览器内存中的引用，加载速度最快
- 但后端无法访问 blob URL
- 所以上传一份到后端，后端用自己的路径访问
```

### 为什么坐标要转换？

```
用户看到的画布是缩放过的:
  原图 1920×1080 → 画布 960×540 (缩放 50%)

用户在画布上点 (480, 270)
SAM 需要原图坐标 (960, 540)

所以: 原图坐标 = 画布坐标 × (原图尺寸 / 画布尺寸)
```

---

## 性能瓶颈在哪？

```
                        耗时        占比       优化方向
─────────────────      ──────      ──────     ─────────
图片上传                50-200ms    5%         压缩后上传
SAM Encoder            600-2000ms  80%        ← 主要瓶颈
SAM Decoder            10-50ms     3%
Mask 编码+传输          20-50ms     5%
前端 Canvas 绘制        5-10ms      1%

优化策略:
1. Encoder 缓存: 同一张图只编码一次（SAM 内部已实现）
2. 混合模式: Encoder 结果传给前端，后续 Decoder 在前端执行
3. 更小模型: SAM2 Tiny (39MB) 比 SAM1 ViT-B (375MB) 快 3-5 倍
```

---

## 文件对照表

| 流程步骤 | 前端文件 | 后端文件 |
|---------|---------|---------|
| 图片上传 | `ImageUploader.vue` | `api/upload.py` |
| 状态管理 | `stores/app.ts` | - |
| 模式实现 | `modes/backend-only/BackendOnlyMode.ts` | - |
| API 调用 | `config/api.ts` | - |
| 图片加载 | - | `core/image_loader.py` |
| SAM 推理 | - | `models/sam1_manager.py` |
| 分割 API | - | `api/segment.py` |
| 画布绘制 | `Canvas/DrawCanvas.vue` | - |
| 模型管理 | - | `models/registry.py` |
